{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from fbprophet import Prophet\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os dados de treinamento\n",
    "train_data = pd.read_excel('../baseDeDados/dataBaseTratada.xlsx')\n",
    "\n",
    "# Carregar os dados de teste\n",
    "test_data = pd.read_excel('../baseDeDados/dataBaseTeste.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cmdstanpy:start chain 1\n",
      "INFO:cmdstanpy:finish chain 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 45\u001b[0m\n\u001b[1;32m     42\u001b[0m test_prophet_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloor\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog1p(\u001b[38;5;241m12.5\u001b[39m)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Fazer previsões nos dados de teste\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m forecast_test \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_prophet_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Aplicar a transformação inversa (exponencial) aos valores previstos\u001b[39;00m\n\u001b[1;32m     48\u001b[0m forecast_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myhat\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpm1(forecast_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myhat\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/prophet/forecaster.py:1275\u001b[0m, in \u001b[0;36mProphet.predict\u001b[0;34m(self, df, vectorized)\u001b[0m\n\u001b[1;32m   1273\u001b[0m seasonal_components \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_seasonal_components(df)\n\u001b[1;32m   1274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muncertainty_samples:\n\u001b[0;32m-> 1275\u001b[0m     intervals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_uncertainty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvectorized\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1276\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1277\u001b[0m     intervals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/prophet/forecaster.py:1440\u001b[0m, in \u001b[0;36mProphet.predict_uncertainty\u001b[0;34m(self, df, vectorized)\u001b[0m\n\u001b[1;32m   1428\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_uncertainty\u001b[39m(\u001b[38;5;28mself\u001b[39m, df: pd\u001b[38;5;241m.\u001b[39mDataFrame, vectorized: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[1;32m   1429\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Prediction intervals for yhat and trend.\u001b[39;00m\n\u001b[1;32m   1430\u001b[0m \n\u001b[1;32m   1431\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1438\u001b[0m \u001b[38;5;124;03m    Dataframe with uncertainty intervals.\u001b[39;00m\n\u001b[1;32m   1439\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1440\u001b[0m     sim_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_posterior_predictive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvectorized\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1442\u001b[0m     lower_p \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterval_width) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m   1443\u001b[0m     upper_p \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterval_width) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/prophet/forecaster.py:1478\u001b[0m, in \u001b[0;36mProphet.sample_posterior_predictive\u001b[0;34m(self, df, vectorized)\u001b[0m\n\u001b[1;32m   1476\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_iterations):\n\u001b[1;32m   1477\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m vectorized:\n\u001b[0;32m-> 1478\u001b[0m         sims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_model_vectorized\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1479\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1480\u001b[0m \u001b[43m            \u001b[49m\u001b[43mseasonal_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseasonal_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1481\u001b[0m \u001b[43m            \u001b[49m\u001b[43miteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1482\u001b[0m \u001b[43m            \u001b[49m\u001b[43ms_a\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomponent_cols\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43madditive_terms\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1483\u001b[0m \u001b[43m            \u001b[49m\u001b[43ms_m\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomponent_cols\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmultiplicative_terms\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1484\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msamp_per_iter\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1486\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1487\u001b[0m         sims \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   1488\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_model(\n\u001b[1;32m   1489\u001b[0m                 df\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1494\u001b[0m             ) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(samp_per_iter)\n\u001b[1;32m   1495\u001b[0m         ]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/prophet/forecaster.py:1554\u001b[0m, in \u001b[0;36mProphet.sample_model_vectorized\u001b[0;34m(self, df, seasonal_features, iteration, s_a, s_m, n_samples)\u001b[0m\n\u001b[1;32m   1552\u001b[0m Xb_m \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmatmul(seasonal_features\u001b[38;5;241m.\u001b[39mvalues, beta \u001b[38;5;241m*\u001b[39m s_m\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[1;32m   1553\u001b[0m \u001b[38;5;66;03m# Get the future trend, which is stochastic per iteration\u001b[39;00m\n\u001b[0;32m-> 1554\u001b[0m trends \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_predictive_trend_vectorized\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# already on the same scale as the actual data\u001b[39;00m\n\u001b[1;32m   1555\u001b[0m sigma \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigma_obs\u001b[39m\u001b[38;5;124m'\u001b[39m][iteration]\n\u001b[1;32m   1556\u001b[0m noise_terms \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(\u001b[38;5;241m0\u001b[39m, sigma, trends\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_scale\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/prophet/forecaster.py:1639\u001b[0m, in \u001b[0;36mProphet.sample_predictive_trend_vectorized\u001b[0;34m(self, df, n_samples, iteration)\u001b[0m\n\u001b[1;32m   1637\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1638\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n\u001b[0;32m-> 1639\u001b[0m uncertainty \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample_uncertainty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1640\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m   1641\u001b[0m     (np\u001b[38;5;241m.\u001b[39mtile(expected, (n_samples, \u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m+\u001b[39m uncertainty) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_scale \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m   1642\u001b[0m     np\u001b[38;5;241m.\u001b[39mtile(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloor\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues, (n_samples, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m   1643\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/prophet/forecaster.py:1681\u001b[0m, in \u001b[0;36mProphet._sample_uncertainty\u001b[0;34m(self, df, n_samples, iteration)\u001b[0m\n\u001b[1;32m   1679\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrowth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogistic\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1680\u001b[0m     mat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_trend_shift_matrix(mean_delta, change_likelihood, n_length, n_samples\u001b[38;5;241m=\u001b[39mn_samples)\n\u001b[0;32m-> 1681\u001b[0m     uncertainties \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_logistic_uncertainty\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1682\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1683\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeltas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeltas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1684\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1685\u001b[0m \u001b[43m        \u001b[49m\u001b[43mm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1686\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfuture_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcap_scaled\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1687\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfuture_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1688\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1689\u001b[0m \u001b[43m        \u001b[49m\u001b[43msingle_diff\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msingle_diff\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1690\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1691\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrowth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflat\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1692\u001b[0m     \u001b[38;5;66;03m# no trend uncertainty when there is no growth\u001b[39;00m\n\u001b[1;32m   1693\u001b[0m     uncertainties \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((n_samples, n_length))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/prophet/forecaster.py:1783\u001b[0m, in \u001b[0;36mProphet._logistic_uncertainty\u001b[0;34m(self, mat, deltas, k, m, cap, t_time, n_length, single_diff)\u001b[0m\n\u001b[1;32m   1781\u001b[0m gammas \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros_like(mat)\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(mat\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]):\n\u001b[0;32m-> 1783\u001b[0m     x \u001b[38;5;241m=\u001b[39m full_t_time[i] \u001b[38;5;241m-\u001b[39m m \u001b[38;5;241m-\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgammas\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1784\u001b[0m     ks \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m k_cum_b[:, i] \u001b[38;5;241m/\u001b[39m k_cum_b[:, i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1785\u001b[0m     gammas[:, i] \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m*\u001b[39m ks\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:2313\u001b[0m, in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2310\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[1;32m   2311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[0;32m-> 2313\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2314\u001b[0m \u001b[43m                      \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:88\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     86\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Preparar os dados de treinamento para Prophet\n",
    "train_prophet_data = train_data[['order_purchase_timestamp', 'delivery_time']].copy()\n",
    "train_prophet_data.rename(columns={'order_purchase_timestamp': 'ds', 'delivery_time': 'y'}, inplace=True)\n",
    "train_prophet_data.dropna(inplace=True)\n",
    "\n",
    "# Aplicar a transformação logarítmica aos valores de 'delivery_time'\n",
    "train_prophet_data['y'] = np.log1p(train_prophet_data['y'])\n",
    "\n",
    "# Definir limites de cap e floor para que o modelo tenda a um valor próximo de 13\n",
    "train_prophet_data['cap'] = np.log1p(13.5)  # valor um pouco maior que 13\n",
    "train_prophet_data['floor'] = np.log1p(12.5)  # valor um pouco menor que 13\n",
    "\n",
    "# Criar e treinar o modelo Prophet com sazonalidades adicionais e ajustes de hiperparâmetros\n",
    "model = Prophet(\n",
    "    growth='logistic',\n",
    "    daily_seasonality=True,\n",
    "    weekly_seasonality=True,\n",
    "    yearly_seasonality=True,\n",
    "    seasonality_mode='multiplicative',\n",
    "    changepoint_prior_scale=0.1,\n",
    "    seasonality_prior_scale=10.0\n",
    ")\n",
    "\n",
    "# Adicionar sazonalidades personalizadas (se aplicável)\n",
    "model.add_seasonality(name='monthly', period=30.5, fourier_order=5)\n",
    "\n",
    "# Treinar o modelo\n",
    "model.fit(train_prophet_data)\n",
    "\n",
    "# Fazer previsões nos dados de treinamento\n",
    "forecast = model.predict(train_prophet_data)\n",
    "\n",
    "# Aplicar a transformação inversa (exponencial) aos valores previstos\n",
    "forecast['yhat'] = np.expm1(forecast['yhat'])\n",
    "\n",
    "# Preparar os dados de teste para Prophet\n",
    "test_prophet_data = test_data[['order_purchase_timestamp']].copy()\n",
    "test_prophet_data.rename(columns={'order_purchase_timestamp': 'ds'}, inplace=True)\n",
    "\n",
    "# Definir cap e floor para os dados de teste\n",
    "test_prophet_data['cap'] = np.log1p(13.5)\n",
    "test_prophet_data['floor'] = np.log1p(12.5)\n",
    "\n",
    "# Fazer previsões nos dados de teste\n",
    "forecast_test = model.predict(test_prophet_data)\n",
    "\n",
    "# Aplicar a transformação inversa (exponencial) aos valores previstos\n",
    "forecast_test['yhat'] = np.expm1(forecast_test['yhat'])\n",
    "\n",
    "# Adicionar previsões ao dataset de teste\n",
    "test_data['previsoes'] = forecast_test['yhat']\n",
    "\n",
    "# Exibir o resultado\n",
    "test_data[['order_purchase_timestamp', 'previsoes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "      <th>previsoes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-11-25 23:51:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-11-29 15:10:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-03 09:44:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-12 15:38:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-17 10:50:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28147</th>\n",
       "      <td>2018-08-29 12:25:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28148</th>\n",
       "      <td>2018-08-29 14:18:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28149</th>\n",
       "      <td>2018-08-29 14:18:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28150</th>\n",
       "      <td>2018-08-29 14:52:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28151</th>\n",
       "      <td>2018-08-29 15:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28152 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      order_purchase_timestamp  previsoes\n",
       "0          2017-11-25 23:51:00        NaN\n",
       "1          2017-11-29 15:10:00        NaN\n",
       "2          2018-01-03 09:44:00        NaN\n",
       "3          2018-01-12 15:38:00        NaN\n",
       "4          2018-01-17 10:50:00        NaN\n",
       "...                        ...        ...\n",
       "28147      2018-08-29 12:25:00        NaN\n",
       "28148      2018-08-29 14:18:00        NaN\n",
       "28149      2018-08-29 14:18:00        NaN\n",
       "28150      2018-08-29 14:52:00        NaN\n",
       "28151      2018-08-29 15:00:00        NaN\n",
       "\n",
       "[28152 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exibir o resultado\n",
    "result = test_data[['previsoes']]\n",
    "result.reset_index(inplace=True)\n",
    "result[['order_purchase_timestamp', 'previsoes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 68.17652877984943\n"
     ]
    }
   ],
   "source": [
    "# Avaliação do modelo\n",
    "mse = mean_squared_error(train_data['delivery_time'], train_data['delivery_time_pred'])\n",
    "print(f'Mean Squared Error: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           order_id  previsoes\n",
      "0  cee3292f46ede6ea1dfabfcb200fcf47  12.797736\n",
      "1  50dca53ca33b739bef09e7933e8b380e  13.258393\n",
      "2  8087ec71e393d4dc6fc48041fe63cd51  11.128320\n",
      "3  e6b6557ce111de79b31cc857f20ba212  13.072897\n",
      "4  0b09c5e4c2512f627190ac55a78c35a3  11.359839\n"
     ]
    }
   ],
   "source": [
    "# Mostrar os resultados\n",
    "print(test_data[['order_id', 'previsoes']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: -310.640917977477\n"
     ]
    }
   ],
   "source": [
    "# Alinhar os índices dos dados reais e previstos para garantir o mesmo tamanho\n",
    "aligned_data = pd.merge(train_prophet_data, forecast[['ds', 'yhat']], on='ds', how='inner')\n",
    "\n",
    "# Calcular o R^2 usando os valores reais e previstos\n",
    "r2 = r2_score(aligned_data['y'], aligned_data['yhat'])\n",
    "print(f'R^2: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enviando para um dataFrame do Kaggle\n",
    "dfKaggle = result[['order_purchase_timestamp', 'previsoes']]\n",
    "\n",
    "# Salvar os resultados\n",
    "dfKaggle.to_csv('../resultadoPrevisoes/previsaoProphet.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
